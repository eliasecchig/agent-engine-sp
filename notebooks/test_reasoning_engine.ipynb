{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Engine - Test Your Remote Agent\n",
    "\n",
    "This notebook demonstrates how to test your agent after deploying it to Agent Engine.\n",
    "You can:\n",
    "- Load your deployed agent using the agent engine ID from deployment\n",
    "- Send test queries and see responses\n",
    "- Stream responses for real-time testing\n",
    "- Test the ability of the agent to register feedback\n",
    "\n",
    "The agent is defined in the [app/agent_engine_app.py](../app/agent_engine_app.py) file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Vertex AI SDK for Python\n",
    "\n",
    "Install the latest version of the Vertex AI SDK for Python as well as extra dependencies related to Reasoning Engine and LangChain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet \"google-cloud-aiplatform[reasoningengine]\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart current runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which will restart the current kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from vertexai.preview import reasoning_engines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the remote Agent Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either specify agent engine ID manually or load from config file\n",
    "REMOTE_AGENT_ENGINE_ID = \"\"  # Manually specify ID here if desired\n",
    "\n",
    "# Load agent engine ID from deployment metadata if not specified manually\n",
    "if REMOTE_AGENT_ENGINE_ID == \"\":\n",
    "    with open(\"../deployment_metadata.json\") as f:\n",
    "        config = json.load(f)\n",
    "        REMOTE_AGENT_ENGINE_ID = config[\"remote_agent_engine_id\"]\n",
    "\n",
    "reasoning_engine = reasoning_engines.ReasoningEngine(REMOTE_AGENT_ENGINE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample input definition\n",
    "\n",
    "We can define a sample input we will use to query our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Hello, AI!\"},\n",
    "        {\"type\": \"ai\", \"content\": \"Hello!\"},\n",
    "        {\"type\": \"user\", \"content\": \"What is the exchange rate from US dollars to Swedish currency?\"},\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the agent\n",
    "We are ready to test the remote agent by sending a synchronous query. The query will block until the response is received.\n",
    "The response will contain the agent's reply to the input messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_engine.query(input=inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also stream responses from the agent.\n",
    "This is useful for long-running queries where you want to see partial results\n",
    "The stream_query method yields chunks of the response as they become available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in reasoning_engine.stream_query(input=inputs): \n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the feedback collection method\n",
    "\n",
    "Finally, we can test the `register_feedback` method we define in the Agent Application. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback = {\n",
    "    \"score\": 1.0,\n",
    "    \"text\": \"This was helpful\",\n",
    "    \"run_id\": \"test-run-123\",\n",
    "    \"log_type\": \"feedback\"\n",
    "}\n",
    "reasoning_engine.register_feedback(feedback=feedback)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
